{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca6db7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating connection to NASA Exoplanet Archive...\n",
      "Downloading stellar catalog (this might take a moment)...\n",
      "Downloading planet host list...\n",
      "Merging datasets and creating binary labels...\n",
      "Data cleaned! Dropped 2942 stars due to missing data.\n",
      "Final dataset size: 197096 stars ready for physics.\n",
      "File saved as 'kepler_clean_demographics.csv'.\n",
      "      kepid   mass   feh   age  has_planet\n",
      "0  10000785  0.635 -1.00  DSEP         0.0\n",
      "1  10000797  0.968 -0.44  DSEP         0.0\n",
      "2  10000800  0.965 -0.04  DSEP         0.0\n",
      "3  10000823  1.191 -0.16  DSEP         0.0\n",
      "4  10000827  0.939 -0.10  DSEP         0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "\n",
    "def fetch_and_clean_data():\n",
    "    print(\"Initiating connection to NASA Exoplanet Archive...\")\n",
    "    \n",
    "    # Switch to the standard API which hosts the legacy Kepler tables\n",
    "    base_url = \"https://exoplanetarchive.ipac.caltech.edu/cgi-bin/nstedAPI/nph-nstedAPI\"\n",
    "    \n",
    "    # 1. We query the Kepler Stellar catalog\n",
    "    print(\"Downloading stellar catalog (this might take a moment)...\")\n",
    "    stellar_params = {\n",
    "        \"table\": \"q1_q17_dr25_stellar\",\n",
    "        \"select\": \"kepid,mass,feh,prov_sec\",\n",
    "        \"format\": \"csv\"\n",
    "    }\n",
    "    stellar_response = requests.get(base_url, params=stellar_params)\n",
    "    \n",
    "    # Check if the API returned an error\n",
    "    if stellar_response.status_code != 200:\n",
    "        raise ValueError(f\"Stellar query failed: {stellar_response.text}\")\n",
    "        \n",
    "    stellar_data = pd.read_csv(io.StringIO(stellar_response.text))\n",
    "    # Rename the column here since the standard API doesn't support 'AS' in the select string\n",
    "    stellar_data = stellar_data.rename(columns={\"prov_sec\": \"age\"})\n",
    "    \n",
    "    # 2. We query the Confirmed Planets/Candidates catalog (The sick people)\n",
    "    print(\"Downloading planet host list...\")\n",
    "    koi_params = {\n",
    "        \"table\": \"q1_q17_dr25_koi\",\n",
    "        \"select\": \"kepid\",\n",
    "        \"where\": \"koi_disposition='CONFIRMED' or koi_disposition='CANDIDATE'\",\n",
    "        \"format\": \"csv\"\n",
    "    }\n",
    "    koi_response = requests.get(base_url, params=koi_params)\n",
    "    \n",
    "    # Check if the API returned an error\n",
    "    if koi_response.status_code != 200:\n",
    "        raise ValueError(f\"KOI query failed: {koi_response.text}\")\n",
    "        \n",
    "    koi_data = pd.read_csv(io.StringIO(koi_response.text))\n",
    "    # Drop duplicates here since the standard API doesn't support 'DISTINCT'\n",
    "    koi_data = koi_data.drop_duplicates(subset=['kepid'])\n",
    "    \n",
    "    # 3. We create our Binary Label (y = 1 or 0)\n",
    "    # If the star's ID is in the koi_data, it gets a 1. Otherwise, 0.\n",
    "    koi_data['has_planet'] = 1\n",
    "    \n",
    "    print(\"Merging datasets and creating binary labels...\")\n",
    "    master_data = pd.merge(stellar_data, koi_data, on='kepid', how='left')\n",
    "    master_data['has_planet'] = master_data['has_planet'].fillna(0)\n",
    "    \n",
    "    # 4. The Clean-Up\n",
    "    # Many stars have missing mass or age.\n",
    "    initial_count = len(master_data)\n",
    "    master_data = master_data.dropna(subset=['mass', 'feh', 'age'])\n",
    "    final_count = len(master_data)\n",
    "    \n",
    "    print(f\"Data cleaned! Dropped {initial_count - final_count} stars due to missing data.\")\n",
    "    print(f\"Final dataset size: {final_count} stars ready for physics.\")\n",
    "    \n",
    "    # Save to our computer\n",
    "    master_data.to_csv(\"kepler_clean_demographics.csv\", index=False)\n",
    "    print(\"File saved as 'kepler_clean_demographics.csv'.\")\n",
    "    \n",
    "    return master_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = fetch_and_clean_data()\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db95f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
